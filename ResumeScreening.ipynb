{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftcOGInOdPbx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from  sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import spacy\n",
        "import pickle\n",
        "\n",
        "df = pd.read_csv('UpdatedResumeDataSet.csv')\n",
        "df['Resume']=df['Resume'].str.replace(r'\\n','')\n",
        "df['Resume']=df['Resume'].str.replace(r'\\r','')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "def preprocess(text):\n",
        "  doc = nlp(text)\n",
        "  filtered_tokens = []\n",
        "  for token in doc:\n",
        "    if token.is_stop or token.is_punct or token.like_email or token.like_url:\n",
        "      continue\n",
        "    filtered_tokens.append(token.lemma_)\n",
        "  return ' '.join(filtered_tokens).strip().lower()\n",
        "\n",
        "df['Processed_Resume'] = df['Resume'].apply(preprocess)"
      ],
      "metadata": {
        "id": "ZySLYUIjlRAU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(df['Category'])\n",
        "df['Category'] = le.transform(df['Category'])\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf.fit(df['Processed_Resume'])\n",
        "processed_text = tfidf.transform(df['Processed_Resume'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(processed_text, df['Category'], test_size=0.2, shuffle=True)\n",
        "\n",
        "clf = KNeighborsClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(precision_score(y_test, y_pred, average='weighted'))\n",
        "print(recall_score(y_test, y_pred, average='weighted'))\n",
        "print(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "pickle.dump(tfidf, open('tfidf.pkl', 'wb'))\n",
        "pickle.dump(clf, open('clf.pkl', 'wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UKV1p35rr3h",
        "outputId": "4686eb1e-dcd3-46ec-a2ed-f6b3e94eafaf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9481865284974094\n",
            "0.9546755489760671\n",
            "0.9481865284974094\n",
            "0.9438657891631533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of Words upto 3-grams\n",
        "clf = Pipeline([('vectorizer', CountVectorizer(ngram_range=(1, 3))), ('knn', KNeighborsClassifier())])\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(precision_score(y_test, y_pred, average='weighted'))\n",
        "print(recall_score(y_test, y_pred, average='weighted'))\n",
        "print(f1_score(y_test, y_pred, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dgP3nzJt7gj",
        "outputId": "7acb8e2c-f716-46c6-ded9-9d881cdfb965"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9585492227979274\n",
            "0.9788191083527871\n",
            "0.9585492227979274\n",
            "0.9604158469170742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['resume_vec'] = df['Processed_Resume'].apply(lambda x: nlp(x).vector)"
      ],
      "metadata": {
        "id": "gl0-yNev02ZU"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spacy word embeddings\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['resume_vec'], df['Category'], test_size=0.2, shuffle=True)\n",
        "X_train_2d = np.stack(X_train)\n",
        "X_test_2d =  np.stack(X_test)\n",
        "\n",
        "clf = KNeighborsClassifier()\n",
        "clf.fit(X_train_2d, y_train)\n",
        "y_pred = clf.predict(X_test_2d)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(precision_score(y_test, y_pred, average='weighted'))\n",
        "print(recall_score(y_test, y_pred, average='weighted'))\n",
        "print(f1_score(y_test, y_pred, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlgAN1K915IK",
        "outputId": "cbd592bb-70d5-4b41-af87-c902f7ec73db"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8704663212435233\n",
            "0.8552437775235703\n",
            "0.8704663212435233\n",
            "0.8559849625627068\n"
          ]
        }
      ]
    }
  ]
}